// DO NOT EDIT.
// swift-format-ignore-file
// swiftlint:disable all
//
// Generated by the Swift generator plugin for the protocol buffer compiler.
// Source: speech.proto
//
// For information on using the generated types, please see the documentation:
//   https://github.com/apple/swift-protobuf/

import Foundation
import SwiftProtobuf

// If the compiler emits an error on this type, it is because this file
// was generated by a version of the `protoc` Swift plug-in that is
// incompatible with the version of SwiftProtobuf to which you are linking.
// Please ensure that you are building against the same version of the API
// that was used to generate this file.
fileprivate struct _GeneratedWithProtocGenSwiftVersion: SwiftProtobuf.ProtobufAPIVersionCheck {
  struct _2: SwiftProtobuf.ProtobufAPIVersion_2 {}
  typealias Version = _2
}

struct Speech_StreamingRecognizeRequest: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  var streamingRequest: Speech_StreamingRecognizeRequest.OneOf_StreamingRequest? = nil

  var streamingConfig: Speech_StreamingRecognitionConfig {
    get {
      if case .streamingConfig(let v)? = streamingRequest {return v}
      return Speech_StreamingRecognitionConfig()
    }
    set {streamingRequest = .streamingConfig(newValue)}
  }

  var audioContent: Data {
    get {
      if case .audioContent(let v)? = streamingRequest {return v}
      return Data()
    }
    set {streamingRequest = .audioContent(newValue)}
  }

  var unknownFields = SwiftProtobuf.UnknownStorage()

  enum OneOf_StreamingRequest: Equatable, Sendable {
    case streamingConfig(Speech_StreamingRecognitionConfig)
    case audioContent(Data)

  }

  init() {}
}

struct Speech_StreamingRecognitionConfig: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  var config: Speech_RecognitionConfig {
    get {_config ?? Speech_RecognitionConfig()}
    set {_config = newValue}
  }
  /// Returns true if `config` has been explicitly set.
  var hasConfig: Bool {self._config != nil}
  /// Clears the value of `config`. Subsequent reads from it will return its default value.
  mutating func clearConfig() {self._config = nil}

  var singleUtterance: Bool = false

  var interimResults: Bool = false

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}

  fileprivate var _config: Speech_RecognitionConfig? = nil
}

struct Speech_RecognitionConfig: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  var encoding: Speech_RecognitionConfig.AudioEncoding = .encodingUnspecified

  var sampleRateHertz: Int32 = 0

  var languageCode: String = String()

  var maxAlternatives: Int32 = 0

  var enableAutomaticPunctuation: Bool = false

  var model: String = String()

  var enableWordTimeOffsets: Bool = false

  var unknownFields = SwiftProtobuf.UnknownStorage()

  enum AudioEncoding: SwiftProtobuf.Enum, Swift.CaseIterable {
    typealias RawValue = Int
    case encodingUnspecified // = 0
    case linear16 // = 1
    case flac // = 2
    case mulaw // = 3
    case amr // = 4
    case amrWb // = 5
    case oggOpus // = 6
    case speexWithHeaderByte // = 7
    case webmOpus // = 9
    case UNRECOGNIZED(Int)

    init() {
      self = .encodingUnspecified
    }

    init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .encodingUnspecified
      case 1: self = .linear16
      case 2: self = .flac
      case 3: self = .mulaw
      case 4: self = .amr
      case 5: self = .amrWb
      case 6: self = .oggOpus
      case 7: self = .speexWithHeaderByte
      case 9: self = .webmOpus
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    var rawValue: Int {
      switch self {
      case .encodingUnspecified: return 0
      case .linear16: return 1
      case .flac: return 2
      case .mulaw: return 3
      case .amr: return 4
      case .amrWb: return 5
      case .oggOpus: return 6
      case .speexWithHeaderByte: return 7
      case .webmOpus: return 9
      case .UNRECOGNIZED(let i): return i
      }
    }

    // The compiler won't synthesize support with the UNRECOGNIZED case.
    static let allCases: [Speech_RecognitionConfig.AudioEncoding] = [
      .encodingUnspecified,
      .linear16,
      .flac,
      .mulaw,
      .amr,
      .amrWb,
      .oggOpus,
      .speexWithHeaderByte,
      .webmOpus,
    ]

  }

  init() {}
}

struct Speech_StreamingRecognizeResponse: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  var results: [Speech_StreamingRecognitionResult] = []

  var speechEventType: Speech_StreamingRecognizeResponse.SpeechEventType = .speechEventUnspecified

  var unknownFields = SwiftProtobuf.UnknownStorage()

  enum SpeechEventType: SwiftProtobuf.Enum, Swift.CaseIterable {
    typealias RawValue = Int
    case speechEventUnspecified // = 0
    case endOfSingleUtterance // = 1
    case UNRECOGNIZED(Int)

    init() {
      self = .speechEventUnspecified
    }

    init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .speechEventUnspecified
      case 1: self = .endOfSingleUtterance
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    var rawValue: Int {
      switch self {
      case .speechEventUnspecified: return 0
      case .endOfSingleUtterance: return 1
      case .UNRECOGNIZED(let i): return i
      }
    }

    // The compiler won't synthesize support with the UNRECOGNIZED case.
    static let allCases: [Speech_StreamingRecognizeResponse.SpeechEventType] = [
      .speechEventUnspecified,
      .endOfSingleUtterance,
    ]

  }

  init() {}
}

struct Speech_StreamingRecognitionResult: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  var alternatives: [Speech_SpeechRecognitionAlternative] = []

  var isFinal: Bool = false

  var stability: Float = 0

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}
}

struct Speech_SpeechRecognitionAlternative: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  var transcript: String = String()

  var confidence: Float = 0

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}
}

// MARK: - Code below here is support for the SwiftProtobuf runtime.

fileprivate let _protobuf_package = "google.cloud.speech.v1"

extension Speech_StreamingRecognizeRequest: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".StreamingRecognizeRequest"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{3}streaming_config\0\u{3}audio_content\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try {
        var v: Speech_StreamingRecognitionConfig?
        var hadOneofValue = false
        if let current = self.streamingRequest {
          hadOneofValue = true
          if case .streamingConfig(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.streamingRequest = .streamingConfig(v)
        }
      }()
      case 2: try {
        var v: Data?
        try decoder.decodeSingularBytesField(value: &v)
        if let v = v {
          if self.streamingRequest != nil {try decoder.handleConflictingOneOf()}
          self.streamingRequest = .audioContent(v)
        }
      }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    switch self.streamingRequest {
    case .streamingConfig?: try {
      guard case .streamingConfig(let v)? = self.streamingRequest else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }()
    case .audioContent?: try {
      guard case .audioContent(let v)? = self.streamingRequest else { preconditionFailure() }
      try visitor.visitSingularBytesField(value: v, fieldNumber: 2)
    }()
    case nil: break
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Speech_StreamingRecognizeRequest, rhs: Speech_StreamingRecognizeRequest) -> Bool {
    if lhs.streamingRequest != rhs.streamingRequest {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Speech_StreamingRecognitionConfig: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".StreamingRecognitionConfig"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{1}config\0\u{3}single_utterance\0\u{3}interim_results\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._config) }()
      case 2: try { try decoder.decodeSingularBoolField(value: &self.singleUtterance) }()
      case 3: try { try decoder.decodeSingularBoolField(value: &self.interimResults) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._config {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    if self.singleUtterance != false {
      try visitor.visitSingularBoolField(value: self.singleUtterance, fieldNumber: 2)
    }
    if self.interimResults != false {
      try visitor.visitSingularBoolField(value: self.interimResults, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Speech_StreamingRecognitionConfig, rhs: Speech_StreamingRecognitionConfig) -> Bool {
    if lhs._config != rhs._config {return false}
    if lhs.singleUtterance != rhs.singleUtterance {return false}
    if lhs.interimResults != rhs.interimResults {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Speech_RecognitionConfig: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".RecognitionConfig"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{1}encoding\0\u{3}sample_rate_hertz\0\u{3}language_code\0\u{3}max_alternatives\0\u{4}\u{4}enable_word_time_offsets\0\u{4}\u{3}enable_automatic_punctuation\0\u{2}\u{2}model\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularEnumField(value: &self.encoding) }()
      case 2: try { try decoder.decodeSingularInt32Field(value: &self.sampleRateHertz) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self.languageCode) }()
      case 4: try { try decoder.decodeSingularInt32Field(value: &self.maxAlternatives) }()
      case 8: try { try decoder.decodeSingularBoolField(value: &self.enableWordTimeOffsets) }()
      case 11: try { try decoder.decodeSingularBoolField(value: &self.enableAutomaticPunctuation) }()
      case 13: try { try decoder.decodeSingularStringField(value: &self.model) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.encoding != .encodingUnspecified {
      try visitor.visitSingularEnumField(value: self.encoding, fieldNumber: 1)
    }
    if self.sampleRateHertz != 0 {
      try visitor.visitSingularInt32Field(value: self.sampleRateHertz, fieldNumber: 2)
    }
    if !self.languageCode.isEmpty {
      try visitor.visitSingularStringField(value: self.languageCode, fieldNumber: 3)
    }
    if self.maxAlternatives != 0 {
      try visitor.visitSingularInt32Field(value: self.maxAlternatives, fieldNumber: 4)
    }
    if self.enableWordTimeOffsets != false {
      try visitor.visitSingularBoolField(value: self.enableWordTimeOffsets, fieldNumber: 8)
    }
    if self.enableAutomaticPunctuation != false {
      try visitor.visitSingularBoolField(value: self.enableAutomaticPunctuation, fieldNumber: 11)
    }
    if !self.model.isEmpty {
      try visitor.visitSingularStringField(value: self.model, fieldNumber: 13)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Speech_RecognitionConfig, rhs: Speech_RecognitionConfig) -> Bool {
    if lhs.encoding != rhs.encoding {return false}
    if lhs.sampleRateHertz != rhs.sampleRateHertz {return false}
    if lhs.languageCode != rhs.languageCode {return false}
    if lhs.maxAlternatives != rhs.maxAlternatives {return false}
    if lhs.enableAutomaticPunctuation != rhs.enableAutomaticPunctuation {return false}
    if lhs.model != rhs.model {return false}
    if lhs.enableWordTimeOffsets != rhs.enableWordTimeOffsets {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Speech_RecognitionConfig.AudioEncoding: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{2}\0ENCODING_UNSPECIFIED\0\u{1}LINEAR16\0\u{1}FLAC\0\u{1}MULAW\0\u{1}AMR\0\u{1}AMR_WB\0\u{1}OGG_OPUS\0\u{1}SPEEX_WITH_HEADER_BYTE\0\u{2}\u{2}WEBM_OPUS\0")
}

extension Speech_StreamingRecognizeResponse: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".StreamingRecognizeResponse"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{2}\u{2}results\0\u{4}\u{2}speech_event_type\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 2: try { try decoder.decodeRepeatedMessageField(value: &self.results) }()
      case 4: try { try decoder.decodeSingularEnumField(value: &self.speechEventType) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.results.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.results, fieldNumber: 2)
    }
    if self.speechEventType != .speechEventUnspecified {
      try visitor.visitSingularEnumField(value: self.speechEventType, fieldNumber: 4)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Speech_StreamingRecognizeResponse, rhs: Speech_StreamingRecognizeResponse) -> Bool {
    if lhs.results != rhs.results {return false}
    if lhs.speechEventType != rhs.speechEventType {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Speech_StreamingRecognizeResponse.SpeechEventType: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{2}\0SPEECH_EVENT_UNSPECIFIED\0\u{1}END_OF_SINGLE_UTTERANCE\0")
}

extension Speech_StreamingRecognitionResult: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".StreamingRecognitionResult"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{1}alternatives\0\u{3}is_final\0\u{1}stability\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedMessageField(value: &self.alternatives) }()
      case 2: try { try decoder.decodeSingularBoolField(value: &self.isFinal) }()
      case 3: try { try decoder.decodeSingularFloatField(value: &self.stability) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.alternatives.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.alternatives, fieldNumber: 1)
    }
    if self.isFinal != false {
      try visitor.visitSingularBoolField(value: self.isFinal, fieldNumber: 2)
    }
    if self.stability.bitPattern != 0 {
      try visitor.visitSingularFloatField(value: self.stability, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Speech_StreamingRecognitionResult, rhs: Speech_StreamingRecognitionResult) -> Bool {
    if lhs.alternatives != rhs.alternatives {return false}
    if lhs.isFinal != rhs.isFinal {return false}
    if lhs.stability != rhs.stability {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Speech_SpeechRecognitionAlternative: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".SpeechRecognitionAlternative"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{1}transcript\0\u{1}confidence\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.transcript) }()
      case 2: try { try decoder.decodeSingularFloatField(value: &self.confidence) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.transcript.isEmpty {
      try visitor.visitSingularStringField(value: self.transcript, fieldNumber: 1)
    }
    if self.confidence.bitPattern != 0 {
      try visitor.visitSingularFloatField(value: self.confidence, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Speech_SpeechRecognitionAlternative, rhs: Speech_SpeechRecognitionAlternative) -> Bool {
    if lhs.transcript != rhs.transcript {return false}
    if lhs.confidence != rhs.confidence {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}
